import 'dart:async';
import 'dart:io';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:path_provider/path_provider.dart';
import 'package:permission_handler/permission_handler.dart';

class AudioStreamService {
  final FlutterSoundRecorder _recorder = FlutterSoundRecorder();
  final StreamController<Uint8List> _audioStreamController =
      StreamController.broadcast();

  // [ì¶”ê°€] ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ ëª¨ìœ¼ëŠ” ë¦¬ìŠ¤íŠ¸
  final List<Uint8List> _audioChunks = [];
  StreamSubscription? _recorderSubscription;

  bool _isInitialized = false;

  Stream<Uint8List> get audioStream => _audioStreamController.stream;

  /// í˜„ì¬ ë…¹ìŒ(ìŠ¤íŠ¸ë¦¬ë°) ì¤‘ì¸ì§€ ì—¬ë¶€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
  bool get isStreaming => _recorder.isRecording;

  Future<void> initialize() async {
    if (_isInitialized) return;

    final status = await Permission.microphone.request();
    if (status != PermissionStatus.granted) {
      throw Exception('Microphone permission not granted');
    }

    await _recorder.openRecorder();
    _isInitialized = true;
    debugPrint("âœ… AudioStreamService (flutter_sound) ì´ˆê¸°í™” ì™„ë£Œ");
  }

  Future<void> startStreaming() async {
    // [ìˆ˜ì •] ë…¹ìŒ ì‹œì‘ ì‹œ í•­ìƒ ì´ˆê¸°í™” í™•ì¸
    await initialize();

    if (_recorder.isRecording) {
      debugPrint("âš ï¸ ì´ë¯¸ ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤.");
      return;
    }

    // [ìˆ˜ì •] ìŠ¤íŠ¸ë¦¼ì„ ì»¨íŠ¸ë¡¤ëŸ¬ë¡œ ë³´ë‚´ê³ , ë™ì‹œì— ë¦¬ìŠ¤íŠ¸ì— ì²­í¬ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    _recorderSubscription = _audioStreamController.stream.listen((chunk) {
      _audioChunks.add(chunk);
    });

    try {
      await _recorder.startRecorder(
        toStream: _audioStreamController.sink,
        codec: Codec.pcm16,
        sampleRate: 16000,
        numChannels: 1,
      );

      debugPrint("ğŸ¤ [AudioStreamService] ë…¹ìŒ ì‹œì‘ë¨");
    } catch (e) {
      debugPrint("âŒ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: $e");
      rethrow;
    }
  }

  // [ìˆ˜ì •] ë…¹ìŒì„ ì¤‘ì§€í•˜ê³ , ì €ì¥ëœ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
  Future<String?> stopStreaming() async {
    if (!_recorder.isRecording) return null;

    await _recorder.stopRecorder();
    await _recorderSubscription?.cancel(); // ë¦¬ìŠ¤ë„ˆ ì •ë¦¬
    debugPrint("ğŸ›‘ [AudioStreamService] ë…¹ìŒ ì¤‘ì§€ë¨. íŒŒì¼ ìƒì„± ì‹œì‘...");

    // [ì¶”ê°€] ë…¹ìŒê¸° ìì› ì¦‰ì‹œ í•´ì œ
    if (_isInitialized) {
      await _recorder.closeRecorder();
      _isInitialized = false;
      debugPrint("ğŸ¤ [AudioStreamService] ë…¹ìŒê¸° ìì› í•´ì œ ì™„ë£Œ.");
    }

    if (_audioChunks.isEmpty) {
      debugPrint("âš ï¸ ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.");
      return null;
    }

    // ëª¨ë“  ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ í•˜ë‚˜ì˜ Uint8Listë¡œ í•©ì¹©ë‹ˆë‹¤.
    final totalBytes = _audioChunks
        .map((c) => c.length)
        .reduce((a, b) => a + b);
    final combinedChunks = Uint8List(totalBytes);
    int offset = 0;
    for (final chunk in _audioChunks) {
      combinedChunks.setAll(offset, chunk);
      offset += chunk.length;
    }
    _audioChunks.clear(); // ë©”ëª¨ë¦¬ ì •ë¦¬

    // WAV íŒŒì¼ í—¤ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    final header = _createWavHeader(combinedChunks.length);

    // í—¤ë”ì™€ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ í•©ì¹©ë‹ˆë‹¤.
    final wavBytes = Uint8List(header.length + combinedChunks.length);
    wavBytes.setAll(0, header);
    wavBytes.setAll(header.length, combinedChunks);

    // íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.
    try {
      final tempDir = await getTemporaryDirectory();
      final filePath = '${tempDir.path}/user_audio.wav';
      final file = File(filePath);
      await file.writeAsBytes(wavBytes, flush: true);
      debugPrint("âœ… [AudioStreamService] WAV íŒŒì¼ ì €ì¥ ì™„ë£Œ: $filePath");
      return filePath;
    } catch (e) {
      debugPrint("âŒ [AudioStreamService] íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: $e");
      return null;
    }
  }

  void dispose() {
    _recorderSubscription?.cancel();
    if (_recorder.isRecording) {
      _recorder.stopRecorder();
    }
    // [ìˆ˜ì •] dispose ì‹œì—ëŠ” ì»¨íŠ¸ë¡¤ëŸ¬ë§Œ ë‹«ë„ë¡ ë³€ê²½ (closeRecorderëŠ” stopStreamingìœ¼ë¡œ ì´ë™)
    _audioStreamController.close();
    debugPrint("ğŸ§¹ AudioStreamService (flutter_sound) ë¦¬ì†ŒìŠ¤ í•´ì œë¨");
  }

  // PCM ë°ì´í„°ë¥¼ ìœ„í•œ WAV íŒŒì¼ í—¤ë”ë¥¼ ìƒì„±í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
  Uint8List _createWavHeader(int dataLength) {
    final byteData = ByteData(44);
    final sampleRate = 16000;
    final numChannels = 1;
    final bitsPerSample = 16;
    final blockAlign = (numChannels * bitsPerSample) ~/ 8;
    final byteRate = sampleRate * blockAlign;

    // RIFF chunk
    byteData.setUint8(0, 0x52); // 'R'
    byteData.setUint8(1, 0x49); // 'I'
    byteData.setUint8(2, 0x46); // 'F'
    byteData.setUint8(3, 0x46); // 'F'
    byteData.setUint32(4, dataLength + 36, Endian.little);

    // WAVE format
    byteData.setUint8(8, 0x57); // 'W'
    byteData.setUint8(9, 0x41); // 'A'
    byteData.setUint8(10, 0x56); // 'V'
    byteData.setUint8(11, 0x45); // 'E'

    // 'fmt ' sub-chunk
    byteData.setUint8(12, 0x66); // 'f'
    byteData.setUint8(13, 0x6d); // 'm'
    byteData.setUint8(14, 0x74); // 't'
    byteData.setUint8(15, 0x20); // ' '
    byteData.setUint32(16, 16, Endian.little); // Sub-chunk1Size
    byteData.setUint16(20, 1, Endian.little); // AudioFormat (1=PCM)
    byteData.setUint16(22, numChannels, Endian.little);
    byteData.setUint32(24, sampleRate, Endian.little);
    byteData.setUint32(28, byteRate, Endian.little);
    byteData.setUint16(32, blockAlign, Endian.little);
    byteData.setUint16(34, bitsPerSample, Endian.little);

    // 'data' sub-chunk
    byteData.setUint8(36, 0x64); // 'd'
    byteData.setUint8(37, 0x61); // 'a'
    byteData.setUint8(38, 0x74); // 't'
    byteData.setUint8(39, 0x61); // 'a'
    byteData.setUint32(40, dataLength, Endian.little);

    return byteData.buffer.asUint8List();
  }
}
